# -*- coding: utf-8 -*-;;;;;
"""tgs2.ipynb";;;;;
;;;;;
Automatically generated by Colaboratory.;;;;;
;;;;;
Original file is located at;;;;;
    https://colab.research.google.com/gist/barcode0725/a7c35c88738ab0126c875feb660848b9/snsscrapetweet.ipynb;;;;;
;;;;;
Klastering data twitter menggunakan keyword lesti dimulai dari tanggal 1-15 Oktober 2022;;;;;
;;;;;
Langkah pertama ialah menginstall snscrape.;;;;;
;;;;;
social networking services atau yang biasa disingkat (SNS) berfungsi untuk mengikis atau memilih data seperti profil pengguna; tagar; atau mencari dan mengumpulkan data yang ditemukan dengan postingan yang relevan.;;;
"""";;;;;
;;;;;
!pip3 install snscrape;;;;;
;;;;;
"""Selanjutnya yaitu menginstall library langdetect.";;;;;
;;;;;
Fungsi dari langdetect untuk mengimplementasi ulang pustaka deteksi bahasa Google ke Python;;;;;
"""";;;;;
;;;;;
pip install langdetect;;;;;
;;;;;
#PROSES INI BERMANFAAT UNTUK MENGIMPOR MODUL SNSCRAPE UNTUK MENANGANI DATA YANG KITA DAPATKAN DARI TWITTER;;;;;
import snscrape.modules.twitter as sntwitter;;;;;
import json;;;;;
from langdetect import detect;;;;;
;;;;;
# DISINI KITA AKAN MEMASUKAN KATA KUNCI DAN RENTANG WAKTU KATA KUNCI YANG AKAN DICARI;;;;;
keywords=['LESTI'];;;;;
"start=""2022–10–01""";;;;;
"end =""2022–10–15""";;;;;
max_num=10;;;;;
fname='tweet.json' ;;;;;
languages=['id';'en'];;;;
;;;;;
"""Lalu mengimport library panda";;;;;
;;;;;
Fungsi dari Library Panda untuk membuat tabel; mengubah dimensi data; mengecek data; dan lain sebagainya. Karena pada Library Panda menyediakan struktur data dan analisis data yang mudah digunakan.;;
;;;;;
"""";;;;;
;;;;;
"#MEMBUAT VARIABEL ""datatw"" UNTUK"; MENAMPILKAN HASIL DATA YANG DIAMBIL DARI TWITTER;;;;
import pandas as pd;;;;;
datatw=[];;;;;
;;;;;
for keyword in keywords:;;;;;
   ;;;;;
    for i; tweet in enumerate (sntwitter.TwitterSearchScraper(f'{keyword} ').get_items()):;;;;
        ;;;;;
        try:;;;;;
            lan=detect(tweet.content);;;;;
        except:;;;;;
            lan='error';;;;;
        if i == max_num:;;;;;
            break;;;;;
        if lan in languages:;;;;;
            data = {'id': tweet.id; 'username':tweet.username; 'date': tweet.date; 'text': tweet.content;'url':tweet.url};
           # print(data);;;;;
            datatw.append(tweet.content);;;;;
            with open(fname; 'a+'; encoding='utf-8') as f:;;;
                line = json.dumps(data; ensure_ascii=False;default=str);;;
                #print(line);;;;;
                f.write(line);;;;;
                f.write('\n');;;;;
;;;;;
datatw;;;;;
;;;;;
"""Langkah selanjutnya ialah menginstall Sastrawi ";;;;;
Sastrawi merupakan library sederhana yang dapat mengubah kata berimbuhan bahasa Indonesia menjadi bentuk dasarnya. ;;;;;
"""";;;;;
;;;;;
!pip install Sastrawi;;;;;
;;;;;
import re;;;;;
import string;;;;;
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer;;;;;
factory = StemmerFactory();;;;;
stemmer = factory.create_stemmer()# stemming process;;;;;
# import StopWordRemoverFactory class;;;;;
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory;;;;;
factory = StopWordRemoverFactory();;;;;
stopword = factory.create_stop_word_remover();;;;;
documents_clean=[];;;;;
;;;;;
for d in datatw:;;;;;
    outputstem= stemmer.stem(d);;;;;
    d= stopword.remove(outputstem);;;;;
    # Remove Unicode;;;;;
    document_test = re.sub(r'[^\x00-\x7F]+'; ' '; d);;;
    # Remove Mentions;;;;;
    document_test = re.sub(r'@\w+'; ''; document_test);;;
    # Lowercase the document;;;;;
    document_test = document_test.lower();;;;;
    # Remove punctuations;;;;;
    document_test = re.sub(r'[%s]' % re.escape(string.punctuation); ' '; document_test);;;
    # Lowercase the numbers;;;;;
    document_test = re.sub(r'[0-9]'; ''; document_test);;;
    # Remove the doubled space;;;;;
    outputstop = re.sub(r'\s{2;}'; ' '; document_test);;
    documents_clean.append(outputstop);;;;;
;;;;;
"""lalu kita akan menggunakan documents_clean untuk menghapus semua karakter tidak dapat dicetak dari teks""";;;;;
;;;;;
documents_clean[0:5];;;;;
;;;;;
"""selanjutnya kita menggunakan TfidfVectorizer untuk membuat matriks padat di mana setiap kolom adalah kata dalam kosakata kita, dan setiap baris sesuai dengan dokumen.""";;;;;
;;;;;
from sklearn.feature_extraction.text import TfidfVectorizer;;;;;
import pandas as pd;;;;;
tfidfvectorizer = TfidfVectorizer(analyzer='word');;;;;
tfidf_wm = tfidfvectorizer.fit_transform(documents_clean);;;;;
tfidf_tokens = tfidfvectorizer.get_feature_names();;;;;
;;;;;
from sklearn.feature_extraction.text import CountVectorizer ;;;;;
import matplotlib.pyplot as plt;;;;;
import numpy as np # linear algebra;;;;;
import pandas as pd # data processing; CSV file I/O (e.g. pd.read_csv);;;;
cv = CountVectorizer() #CountVectorizer; berfungsi untuk menghitung frekuensi kata dalam dokumen.;;;;
words = cv.fit_transform(documents_clean);;;;;
sum_words = words.sum(axis=0);;;;;
;;;;;
;;;;;
words_freq = [(word; sum_words[0; idx]) for word; idx in cv.vocabulary_.items()];;
words_freq = sorted(words_freq; key = lambda x: x[1]; reverse = True);;;
frequency = pd.DataFrame(words_freq; columns=['word'; 'freq']);;;
;;;;;
color = plt.cm.twilight(np.linspace(0;1; 20));;;
frequency.head(20).plot(x='word'; y='freq'; kind='bar'; figsize=(15; 7); color = color)
"plt.title(""Most Frequently Occuring Words - Top 20"")";;;;;
;;;;;
## IMPORT K-MEANS UNTUK PROSES CLUSTERING;;;;;
from sklearn.cluster import KMeans;;;;;
true_k = 3;;;;;
model = KMeans(n_clusters=true_k; init='k-means++'; max_iter=100; n_init=1);;
model.fit(words);;;;;
;;;;;
# LAKUKAN ORDER CENTROID; UNTUK MEMBERIKAN HASIL UNTUK DI SETIAP CLUSTER;;;;
order_centroids = model.cluster_centers_.argsort()[:; ::-1];;;;
terms = cv.get_feature_names();;;;;
;;;;;
for i in range(true_k):;;;;;
"    print(""Cluster %d:"" % i)";;;;;
    for ind in order_centroids[i; :10]:;;;;
        print(' %s' % terms[ind]);;;;;
    print;;;;;
;;;;;
"print(""\n"")";;;;;
;;;;;
#UNTUK MELIHAT DIAGRAM DENDROGRAM DARI BAWAH KEATAS;;;;;
import scipy.cluster.hierarchy as sch;;;;;
X = cv.fit_transform(documents_clean).todense();;;;;
dendrogram = sch.dendrogram(sch.linkage(X; method = 'ward';metric='euclidean');"orientation=""top"")";;
#Fungsi Method ward untuk melakukan metode pembentukan cluster yang di dasari oleh hilangnya informasi akibat penggabungan obyek menjadi cluster.;;;;;
plt.title('Dendrogram');;;;;
plt.xlabel('Jarak Ward');;;;;
plt.ylabel('Nomor Dokumen');;;;;
plt.show();;;;;
;;;;;
#UNTUK MELIHAT DIAGRAM DENDROGRAM DARI KIRI KEKANAN;;;;;
import scipy.cluster.hierarchy as sch;;;;;
X = cv.fit_transform(documents_clean).todense();;;;;
dendrogram = sch.dendrogram(sch.linkage(X; method = 'average';metric='euclidean');"orientation=""right"") ";;
plt.title('Dendrogram');;;;;
plt.xlabel('Jarak Rerata');;;;;
plt.ylabel('Nomor Dokumen');;;;;
plt.show();;;;;
;;;;;
"""https://www.freecodecamp.org/news/python-web-scraping-tutorial/";;;;;
https://medium.com/dataseries/how-to-scrape-millions-of-tweets-using-snscrape-195ee3594721;;;;;
"""";;;;;
